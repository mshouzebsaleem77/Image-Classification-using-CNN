{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense  #droput is used for prevention of overfitting, flatten convert into single array\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " # dimension of our images\n",
    "    \n",
    "img_width, img_height=150, 150\n",
    "\n",
    "train_data_dir='training_set' #Please Add your respective Path\n",
    "test_data_dir='test_set' #PLease Add Your Respective Path\n",
    "nb_train_samples=1000\n",
    "nb_test_samples=100\n",
    "epochs=50   #no of times you will sent batch of data  here we give 20 images to neural network 50 times\n",
    "batch_size=20 #no of images you are giving at one point of time\n",
    "\n",
    "if K.image_data_format()=='channels_first':\n",
    "    input_shape=(3, img_width, img_height)\n",
    "else:\n",
    "    input_shape=(img_width, img_height,3) #150,150,3\n",
    "\n",
    "train_datagen= ImageDataGenerator(\n",
    "    rescale=1. /255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)    \n",
    "\n",
    "#for test data\n",
    "test_datagen= ImageDataGenerator(rescale=1. /255)\n",
    "\n",
    "\n",
    "train_generator= train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "\n",
    "test_generator= test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width,img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "    \n",
    "\n",
    "#implementig a neural network\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.summary()\n",
    "          \n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))  #dense give you a hidden layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='rmsprop',\n",
    "             metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 364s 364ms/step - loss: 0.6472 - acc: 0.6365 - val_loss: 0.5517 - val_acc: 0.7220\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 356s 356ms/step - loss: 0.5621 - acc: 0.7189 - val_loss: 0.5056 - val_acc: 0.7615\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 310s 310ms/step - loss: 0.5188 - acc: 0.7541 - val_loss: 0.4744 - val_acc: 0.7852\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 0.4926 - acc: 0.7716 - val_loss: 0.4568 - val_acc: 0.7968\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 220s 220ms/step - loss: 0.4732 - acc: 0.7851 - val_loss: 0.4438 - val_acc: 0.7993\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 241s 241ms/step - loss: 0.4622 - acc: 0.7912 - val_loss: 0.4170 - val_acc: 0.8180\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 276s 276ms/step - loss: 0.4426 - acc: 0.8058 - val_loss: 0.4510 - val_acc: 0.7847\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 273s 273ms/step - loss: 0.4400 - acc: 0.8082 - val_loss: 0.3827 - val_acc: 0.8422\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 0.4271 - acc: 0.8176 - val_loss: 0.5187 - val_acc: 0.8210\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 221s 221ms/step - loss: 0.4240 - acc: 0.8189 - val_loss: 0.4420 - val_acc: 0.8195\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4134 - acc: 0.8246 - val_loss: 0.3915 - val_acc: 0.8527\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.4222 - acc: 0.8262 - val_loss: 0.4184 - val_acc: 0.8109\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: 0.4092 - acc: 0.8303 - val_loss: 0.5422 - val_acc: 0.7796\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 276s 276ms/step - loss: 0.4102 - acc: 0.8321 - val_loss: 0.3985 - val_acc: 0.8507\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 274s 274ms/step - loss: 0.4010 - acc: 0.8322 - val_loss: 0.3641 - val_acc: 0.8452\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 253s 253ms/step - loss: 0.3958 - acc: 0.8350 - val_loss: 0.4557 - val_acc: 0.8437\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 242s 242ms/step - loss: 0.4020 - acc: 0.8356 - val_loss: 0.4102 - val_acc: 0.8558\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 231s 231ms/step - loss: 0.3990 - acc: 0.8390 - val_loss: 0.4228 - val_acc: 0.8371\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.3979 - acc: 0.8383 - val_loss: 0.4700 - val_acc: 0.7867\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4036 - acc: 0.8381 - val_loss: 0.3715 - val_acc: 0.8618\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4072 - acc: 0.8376 - val_loss: 0.3807 - val_acc: 0.8649\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 224s 224ms/step - loss: 0.4121 - acc: 0.8330 - val_loss: 0.3886 - val_acc: 0.8598\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4117 - acc: 0.8329 - val_loss: 0.4020 - val_acc: 0.8235\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4046 - acc: 0.8358 - val_loss: 0.3672 - val_acc: 0.8613\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4121 - acc: 0.8333 - val_loss: 0.3558 - val_acc: 0.8538\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 225s 225ms/step - loss: 0.4167 - acc: 0.8298 - val_loss: 0.3980 - val_acc: 0.8522\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4270 - acc: 0.8277 - val_loss: 0.3718 - val_acc: 0.8583\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 234s 234ms/step - loss: 0.4187 - acc: 0.8304 - val_loss: 0.3852 - val_acc: 0.8285\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4378 - acc: 0.8285 - val_loss: 0.4253 - val_acc: 0.8200\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 226s 226ms/step - loss: 0.4331 - acc: 0.8222 - val_loss: 0.4379 - val_acc: 0.8512\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4482 - acc: 0.8208 - val_loss: 0.4220 - val_acc: 0.8099\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4360 - acc: 0.8247 - val_loss: 0.5825 - val_acc: 0.8149\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 222s 222ms/step - loss: 0.4432 - acc: 0.8189 - val_loss: 0.3849 - val_acc: 0.8477\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4440 - acc: 0.8215 - val_loss: 0.4630 - val_acc: 0.8613\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4529 - acc: 0.8202 - val_loss: 0.3397 - val_acc: 0.8830\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4566 - acc: 0.8231 - val_loss: 0.3894 - val_acc: 0.8487\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4693 - acc: 0.8097 - val_loss: 0.3623 - val_acc: 0.8593\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 243s 243ms/step - loss: 0.4729 - acc: 0.8122 - val_loss: 0.5446 - val_acc: 0.6944\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 233s 233ms/step - loss: 0.4571 - acc: 0.8214 - val_loss: 0.3756 - val_acc: 0.8578\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 0.4683 - acc: 0.8128 - val_loss: 0.4840 - val_acc: 0.8472\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 271s 271ms/step - loss: 0.5686 - acc: 0.8075 - val_loss: 0.8355 - val_acc: 0.7943\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 248s 248ms/step - loss: 0.4740 - acc: 0.8172 - val_loss: 0.6096 - val_acc: 0.8124\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 223s 223ms/step - loss: 0.4709 - acc: 0.8146 - val_loss: 0.4317 - val_acc: 0.8467\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 225s 225ms/step - loss: 0.4771 - acc: 0.8102 - val_loss: 0.4182 - val_acc: 0.8185\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 265s 265ms/step - loss: 0.4700 - acc: 0.8115 - val_loss: 0.4556 - val_acc: 0.8633\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 0.4869 - acc: 0.8016 - val_loss: 0.4133 - val_acc: 0.8210\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 235s 235ms/step - loss: 0.4927 - acc: 0.8011 - val_loss: 0.4814 - val_acc: 0.8174\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 245s 245ms/step - loss: 0.5006 - acc: 0.8003 - val_loss: 0.4843 - val_acc: 0.8396\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 236s 236ms/step - loss: 0.5151 - acc: 0.7964 - val_loss: 0.5307 - val_acc: 0.8119\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 252s 252ms/step - loss: 0.5457 - acc: 0.7854 - val_loss: 0.6466 - val_acc: 0.8195\n"
     ]
    }
   ],
   "source": [
    "#training part\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=nb_test_samples)\n",
    "    \n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "#testing and prediction\n",
    "\n",
    "img_pred=image.load_img('C:\\\\Users\\\\OwNer\\\\Image Classification\\\\test_set\\\\test_set\\\\dogs\\\\dog.4020.jpg', target_size=(150,150))\n",
    "img_pred=image.img_to_array(img_pred)\n",
    "img_pred=np.expand_dims(img_pred, axis=0)\n",
    "\n",
    "\n",
    "rslt=model.predict(img_pred)\n",
    "print(rslt)\n",
    "\n",
    "if rslt[0][0]==1:\n",
    "    prediction='dog'\n",
    "else:\n",
    "    prediction='cat'\n",
    "\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
